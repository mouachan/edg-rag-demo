apiVersion: batch/v1
kind: Job
metadata:
  name: gemma-embedding-download
  namespace: edg-demo
  labels:
    app: gemma-embedding-download
spec:
  backoffLimit: 3
  template:
    metadata:
      labels:
        app: gemma-embedding-download
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - eu-central-1a
      containers:
      - name: download-model
        image: python:3.11-slim
        command:
        - /bin/bash
        - -c
        - |
          set -e

          echo "=========================================="
          echo "Gemma Embedding Model Download Job"
          echo "=========================================="
          echo ""

          # Install dependencies
          echo "Installing dependencies..."
          pip install --no-cache-dir --target=/tmp/pip-packages huggingface-hub
          export PYTHONPATH=/tmp/pip-packages:$PYTHONPATH

          # Set HuggingFace cache directory
          export HF_HOME=/models/cache
          mkdir -p $HF_HOME

          # Download model
          echo ""
          echo "Downloading google/embeddinggemma-300m..."
          echo "This may take 5-10 minutes depending on network speed"
          echo ""

          python3 << 'EOF'
          from huggingface_hub import snapshot_download
          import os

          model_id = "google/embeddinggemma-300m"
          local_dir = "/models/gemma-embedding-300m"

          print(f"Downloading {model_id}...")
          print(f"Destination: {local_dir}")

          snapshot_download(
              repo_id=model_id,
              local_dir=local_dir,
              local_dir_use_symlinks=False,
              resume_download=True
          )

          print("\nâœ“ Download complete!")
          print(f"Model saved to: {local_dir}")

          # List downloaded files
          print("\nDownloaded files:")
          for root, dirs, files in os.walk(local_dir):
              for file in files:
                  filepath = os.path.join(root, file)
                  size = os.path.getsize(filepath) / (1024**2)  # MB
                  print(f"  {file}: {size:.2f} MB")
          EOF

          echo ""
          echo "=========================================="
          echo "Download Complete!"
          echo "=========================================="
          echo ""
          echo "Model location: /models/gemma-embedding-300m"
          echo "Total size:"
          du -sh /models/gemma-embedding-300m
        env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              key: token
              name: huggingface-token
        resources:
          limits:
            cpu: "1"
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
        volumeMounts:
        - mountPath: /models
          name: model-storage
      restartPolicy: OnFailure
      tolerations:
      - effect: NoSchedule
        key: nvidia.com/gpu
        operator: Equal
        value: NVIDIA-L40-PRIVATE
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: gemma-embedding-storage
